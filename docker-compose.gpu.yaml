services:
  triton_hf:
    build:
      context: .
      dockerfile: Dockerfiles/triton/Dockerfile
      target: development-gpu
      args:
        - FROM_IMAGE_NAME=nvcr.io/nvidia/pytorch:24.03-py3
    shm_size: '64gb'
    restart: unless-stopped
    command: [ "python3", "-m", "triton_server","--verbose" ]
    ports:
      - 8500:8000
      - 8501:8001
      - 8502:8002
    environment:
      - LC_ALL=C.UTF-8
      - LANG=C.UTF-8
    volumes:
      - ./triton_server:/src/triton_server
      - ./models:/src/models
    deploy:
      resources:
        limits:
          cpus: '12'
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['2']
            capabilities: [gpu]